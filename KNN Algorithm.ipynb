{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](KNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although KNN can be used both for regression, and classification, it is widely used for classification. The algorithm adopts the lazy learning method. In other words, instead of learning the training data set, it memorizes it and decides according to the nearest neighbor when a prediction is requested. The **K** is the number of values to look around. When a value is determined, the nearest k values are taken and the distance is calculated with the Euclidean equation. Manhattan, and Minkowski functions can also be used when calculating the distance.\n",
    "\n",
    "> 1. In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    "> 2. In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.saedsayad.com/images/KNN_similarity.png)\n",
    "<a href = \"https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.saedsayad.com%2Fk_nearest_neighbors.htm&psig=AOvVaw0oM7BHmV-PgxsO4TpoAhlN&ust=1623933152509000&source=images&cd=vfe&ved=0CA0QjhxqFwoTCJCpjciUnPECFQAAAAAdAAAAABAD\">Image Source</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNearestNeighbor():\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        distances = self.compute_distance(X_test)\n",
    "        return self.predict_labels(distances)\n",
    "        \n",
    "    def compute_distance(self, X_test):\n",
    "        num_test = X_test.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        distances = np.zeros((num_test, num_train))\n",
    "        \n",
    "        for i in range(num_test):\n",
    "            for j in range(num_train):\n",
    "                # euclidean distance\n",
    "                distances[i, j] = np.sqrt(np.sum((X_test[i, :] - self.X_train[j, :])**2))\n",
    "                \n",
    "        return distances\n",
    "        \n",
    "    def predict_labels(self, distances):\n",
    "        num_test = distances.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        \n",
    "        for i in range(num_test):\n",
    "            # giving the indices of the elements after sorting\n",
    "            y_indices = np.argsort(distances[i, :])\n",
    "            k_closest_classes = self.y_train[y_indices[:self.k]].astype(int)\n",
    "            # count number of occurrences of each value in array of non-negative ints\n",
    "            y_pred[i] = np.argmax(np.bincount(k_closest_classes))\n",
    "        return y_pred\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    X = np.loadtxt(\"data.txt\",\n",
    "                  delimiter = \",\")\n",
    "    y = np.loadtxt(\"targets.txt\",\n",
    "                  delimiter = \",\")\n",
    "    KNN = KNearestNeighbor(k = 3)\n",
    "    KNN.train(X, y)\n",
    "    y_pred = KNN.predict(X)\n",
    "    print(f\"Accuracy: {sum(y_pred == y)/ y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href = \"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#:~:text=In%20statistics%2C%20the%20k%2Dnearest,training%20examples%20in%20data%20set.\">Wikipedia</a>\n",
    "2. <a href = \"https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\">Analytics Vidhya</a>\n",
    "3. <a href = \"https://medium.com/@ekrem.hatipoglu/machine-learning-classification-k-nn-k-en-yak%C4%B1n-kom%C5%9Fu-part-9-6f18cd6185d\">Medium</a>\n",
    "4. <a href = \"https://www.youtube.com/watch?v=QzAaRuDskyc\">Aladdin Persson</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
